import pandas as pd
from pathlib import Path


def prepare_ml_training_data_fixed():
    """
    (ìˆ˜ì •) ì†ë„ ë°ì´í„°ì˜ íƒ€ì…ì„ ìˆ«ìë¡œ ëª…í™•í•˜ê²Œ ë³€í™˜í•˜ì—¬
    ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµì— ì í•©í•œ ìµœì¢… ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    print("ğŸš€ 1ë‹¨ê³„ (ìˆ˜ì •): AI í•™ìŠµìš© ë°ì´í„° ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    try:
        df_congestion = pd.read_csv(PROJECT_ROOT / "data/ultimate_final-final_hourly_congestion.csv")
        df_speed = pd.read_csv(PROJECT_ROOT / "source/AverageSpeed(LINK).csv")
        print("âœ… 2ê°œì˜ ì†ŒìŠ¤ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: '{e.filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # --- 2. ë°ì´í„° ì •ì œ ë° ì¬êµ¬ì„± ---
    print("â³ ë°ì´í„°ë¥¼ ì •ì œí•˜ê³  AIê°€ í•™ìŠµí•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤...")

    # [2-1] í˜¼ì¡ë„ ë°ì´í„° ì¬êµ¬ì„± (ì´ì „ê³¼ ë™ì¼)
    congestion_long = pd.melt(
        df_congestion,
        id_vars=['LINK ID'],
        value_vars=[f'Final_Congestion_Hour_{i}' for i in range(24)],
        var_name='hour_str',
        value_name='congestion'
    )
    congestion_long['hour'] = congestion_long['hour_str'].str.extract(r'(\d+)').astype(int)
    congestion_long.drop(columns='hour_str', inplace=True)

    # [2-2] ì†ë„ ë°ì´í„° ì •ì œ ë° ì¬êµ¬ì„±
    speed_time_cols = [f'{i}~{i + 1}ì‹œ' for i in range(24)]
    df_speed.rename(columns={'5.5 LINK ID': 'LINK ID'}, inplace=True)

    # (âœ¨ í•µì‹¬ ìˆ˜ì •!) ì†ë„ ì»¬ëŸ¼ë“¤ì„ ê°•ì œë¡œ ìˆ«ì íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    # ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ê°’(ì˜ˆ: í…ìŠ¤íŠ¸)ì€ NaN(ê²°ì¸¡ì¹˜)ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
    for col in speed_time_cols:
        df_speed[col] = pd.to_numeric(df_speed[col], errors='coerce')

    speed_long = pd.melt(
        df_speed,
        id_vars=['LINK ID'],
        value_vars=speed_time_cols,
        var_name='hour_str',
        value_name='speed'
    )
    speed_long['hour'] = speed_long['hour_str'].str.extract(r'^(\d+)').astype(int)
    speed_long.drop(columns='hour_str', inplace=True)

    print("âœ… ë°ì´í„° ì •ì œ ë° ì¬êµ¬ì„± ì™„ë£Œ.")

    # --- 3. ìµœì¢… ë°ì´í„° ê²°í•© ë° ì €ì¥ ---
    print("â³ ì¬êµ¬ì„±ëœ ë‘ ë°ì´í„°ë¥¼ ìµœì¢… ê²°í•©í•©ë‹ˆë‹¤...")

    df_final_ml = pd.merge(congestion_long, speed_long, on=['LINK ID', 'hour'])
    df_final_ml.dropna(inplace=True)  # speedê°€ NaNì¸ í–‰ë“¤ì´ ì—¬ê¸°ì„œ ì œê±°ë©ë‹ˆë‹¤.
    df_final_ml['LINK ID'] = df_final_ml['LINK ID'].astype(int)

    output_filename = PROJECT_ROOT / 'data/ml_training_data.csv' # ê²½ë¡œ ìˆ˜ì •
    df_final_ml.to_csv(output_filename, index=False, encoding='utf-8-sig')

    print(f"\nğŸ‰ 1ë‹¨ê³„ ì„±ê³µ! AI í•™ìŠµìš© ë¬¸ì œì§‘ '{output_filename}'ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"  - ì´ {len(df_final_ml)}ê°œì˜ í•™ìŠµ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("\n[ìƒì„±ëœ ë°ì´í„° ìƒ˜í”Œ]")
    print(df_final_ml.head())


if __name__ == '__main__':
    prepare_ml_training_data_fixed()